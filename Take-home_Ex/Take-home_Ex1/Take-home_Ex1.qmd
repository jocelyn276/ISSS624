---
title: "Take-home Exercise 1"
execute:
  warning: false
  message: false
date: 2022-11-30
date-format: long
editor: visual
---

## 1. Overview

### 1.1 Background

Water is important resource to mankind. Clean and accessible water is critical to human health. As water is finite, various environmental problems and increasing population have intensified water scarcity. According to UN-Water, 1.8 billion people will be living in countries or regions with absolute water scarcity by 2025. Water also poses threats to other factors, such as food security.

Developing countries are more affected by water shortage and poor water quality. In this project, Nigeria, a country in West Africa, will be used as the study country. We are going to apply appropriate global and local measures of spatial Association techniques to reveals the spatial patterns of Not Functional water points.

### 1.2 Problem Statement

The analysis aims to reveal the spatial patterns of Not Functional water points in Nigeria with following:

-   Using tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level;

-   Performing outliers/clusters analysis by using local measures of spatial association methods;

-   Performing hotspot areas analysis by using local measures of spatial association methods.

### 1.3 Data

#### Aspatial data

Data from [Water Point Data Exchange(WPdx)](https://www.waterpointdata.org/access-data/) in WPdx+, an enhanced version of WPdx-Basic dataset.

#### Geospatial data

Nigeria Level-2 Administrative Boundary(local government area), which can be downloaded from <https://data.humdata.org/dataset/cod-ab-nga>.

### 1.4 R package

The packages will be used for this analysis:

***sf***: used for importing, managing and processing geospatial data

***tidyverse***: a set of packages for data science

***tmap***: used to generate thematic maps

***spdep***: used to create spatial weights matrix objects

***funModeling***: used for rapid Exploratory Data Analysis

The code chunk below is used for load related packages into R environment.

```{r}
pacman::p_load(sf, tidyverse, tmap, spdep, funModeling)
```

## 2. Data Wrangling

Following two datasets are used:

| File Name                       | Data Type       |
|---------------------------------|-----------------|
| geo_export                      | aspatial data   |
| nga_admbnda_adm2_osgof_20190417 | geospatial data |

### 2.1 Importing Water Point Data

```{r}
#| eval: false
wp <- st_read(dsn="geodata",
              layer="geo_export",
              crs=4326) %>%
  filter(clean_coun == "Nigeria")
```

`write_rds` is used to save the extracted sf data table into an output file in *rds* data format.

```{r}
#| eval: false
wp_nga <- write_rds(wp,
                    "geodata/wp_nga.rds")
```

### 2.2 Importing Nigeria LGA Boundary data

```{r}
#| eval: false
nga <- st_read(dsn="geodata",layer="nga_admbnda_adm2_osgof_20190417",
               crs=4326)
```

### 2.3 Data Processing

#### 2.3.1 Recode NA value into Unknown

```{r}
#| eval: false
wp_nga <- read_rds("geodata/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

### 2.4 Explanatory Data Analysis

The code chunk below is used to display the distribution of *status_cle.*

```{r}
#| eval: false
freq (data=wp_nga,input = "status_cle")
```

![](images/paste-DB146C1E.png){width="464"}

Above figure shows that there are 9 kinds of status. For the convenience of analysis, we are going to define three categories for water points: "Functional", "Non-Functional" and " Unknown". "Functional", "Functional but needs repair", "Functional but not in use" will be categorized to "Functional" while "Non-Functional", "Non-Functional due to dry season", "Non functional due to dry season", "Abandoned", "Abandoned/Decommissioned" will be categorized to "Non-Functional".

### 2.5 Extract Water Points(Functional, Non-Functional and Unknown)

The code chunk below is used to extract functional, non-functional and unknown water points respectively.

```{r}
#| eval: false
wpt_functional <- wp_nga %>%
  filter(status_cle %in%
           c("Functional", 
             "Functional but not in use",
             "Functional but needs repair"))
freq(data=wpt_functional, input="status_cle")
```

```{r}
#| eval: false
wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
freq(data=wpt_nonfunctional,input = 'status_cle')
```

```{r}
#| eval: false
wpt_unknown <- wp_nga %>%
  filter(status_cle == "Unknown")
```

### 2.6 Performing Point-in-Polygon Count

The code chunk below is used to calculate numbers of each category water points in Nigeria.

```{r}
#| eval: false
nga_wp <- nga %>% 
  mutate(`total wpt` = lengths(
    st_intersects(nga, wp_nga))) %>%
  mutate(`wpt functional` = lengths(
    st_intersects(nga, wpt_functional))) %>%
  mutate(`wpt non-functional` = lengths(
    st_intersects(nga, wpt_nonfunctional))) %>%
  mutate(`wpt unknown` = lengths(
    st_intersects(nga, wpt_unknown)))
```

### 2.7 Saving the analytical data table

The code chunk below is used to derive two columns named *pct_functional* and *pct_non-functional* to show percentage of each category water point in Nigeria. And to keep the file size small, `select` of **dplyr** is used to retain field 3,4,9,10,18,19,20,21,22 and 23.

```{r}
#| eval: false
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt functional`/`total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`) %>%
  select(3:4, 9:10, 18:23)
```

Now the tidy version of sf data table is attainable, we can save it into *rds* format.

```{r}
#| eval: false
write_rds(nga_wp, "geodata/nga_wp.rds")
```

The code chunk below is used to read the *rds* file into R environment.

```{r}
nga_wp <- read_rds("geodata/nga_wp.rds")
```

Before conducting the analysis, we can have a glimpse of our data table by using following code chunk.

```{r}
glimpse(nga_wp)
```

There are 774 local government areas with 11 columns.

### 2.8 Working with Projection

The code chunk below is used to check the coordinate reference system.

```{r}
st_crs(nga_wp)
```

The CRS is WGS 84, EPSG 4326. Because our study country is Nigeria, so the Projected Coordinate System should be changed to one of following EPSG: 26391, 26392, and 26303. The code chunk below is used to change EPSG to 26391 and check.

```{r}
nga_wp<- st_transform(nga_wp, 26391)
st_crs(nga_wp)
```

## 3. Mapping: Functional and Non-funtional water point rate

The code chunk below is used to display the spatial distribution of the number of each category water points.

```{r}
tm_shape(nga_wp)+ 
  tm_polygons(c("total wpt","wpt functional","wpt non-functional","wpt unknown")) +
  tm_layout(legend.width=0.2,
          legend.height=0.3,
          legend.position=c("right","bottom"))
```

Apart from the number, the distribution of functional and non-functional water point rate at LGA level is going to be plotted below.

```{r}
tm_shape(nga_wp)+ 
  tm_polygons(c("pct_functional","pct_non-functional")) +
  tm_layout(legend.width=0.2,
          legend.height=0.3,
          legend.position=c("right","bottom"))
```

Observations from above choropleth maps:

-   Functional water points mainly located in the north and east of Nigeria.
-   There are some missing values in the northeast part of Nigeria.
-   The distribution of non-functional water points seems to have certain spatial autocorrelation(will test in the following chapter).

### Dealing with the missing data

The code chunk below is used to show the rows have missing data for colomn "pct_non-functional".

```{r}
which(is.na(nga_wp$`pct_non-functional`))
```

There are 13 columns that do not have the percentage value. Because the numbers of their total water points are 0, and respective percentage shows as NaN. The code chunk below is used to fill NaN with 0.

```{r}
nga_wp$`pct_non-functional`[is.na(nga_wp$`pct_non-functional`)] = 0
nga_wp$`pct_functional`[is.na(nga_wp$`pct_functional`)] = 0
```

Let's check the choropleth map again.

```{r}
pct_functional <- tm_shape(nga_wp)+ 
  tm_polygons("pct_functional") +
  tm_layout(legend.width=0.2,
          legend.height=0.3,
          legend.position=c("right","bottom"))

pct_nonfunctional <- tm_shape(nga_wp)+ 
  tm_polygons("pct_non-functional") +
  tm_layout(legend.width=0.2,
          legend.height=0.3,
          legend.position=c("right","bottom"))

tmap_arrange(pct_functional, pct_nonfunctional, asp=1, ncol=2)
```

The missing data have been changed to 0.

## 4. Computing Contiguity Spatial Weights

Before computing the global spatial autocorrelation statistics, it is necessary to construct a spatial weights. The spatial weights is used to define the neighbourhood relationships between the local government areas in Nigeria.

### 4.1 Selecting the spatial weighing method

First of all, we need to select an appropriate spatial weighing method to calculate the spatial weight matrix.

#### Polygon Contiguity Method

The **polygon contiguity method** is effective when polygons are similar in size and distribution, and when spatial relationships are a function of polygon proximity (the idea that if two polygons share a boundary, spatial interaction between them increases).

The code chunk below is used to show the boundary line of LGA in Nigeria.

```{r}
nigeria_lga <- tm_shape(nga_wp) +
  tm_polygons()
nigeria_lga
```

The size and distribution of LGA in Nigeria is not similar. Some LGAs are more dense and have shorter boundary.

#### Distance-based neighbours

To use distance-based method, the first step is to get the centroid of each polygon by running *st_centroid* on the **sf** package.

```{r}
coords <- st_centroid(st_geometry(nga_wp))
```

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first-nearest neighbour distance is 72139 m, which will be used as the upper threshold in order to make sure all LGA will have at least one neighbour.

#### Computing fixed distance weight matrix

The **fixed distance method** often is a good option for polygon data when there is a large variation in polygon size.

```{r}
upper_threshold <- 73000
wm_d <- dnearneigh(coords, 0, upper_threshold, longlat = TRUE)
wm_d
```

The report shows that the average number of links for each region is 23.88, which may be skewed for the analysis.

#### Computing adaptive distance weight matrix

Adaptive distance can adjust itself according to the density of data. K-nearest neighbours can be used to control the numbers of neighbours directly. The numbers of neighbours can be assigned to the argument of *knearhneigh()* and the neighbours can be designated based on the distance between centroids.

The code chunk below is used to control the numbers of neighbours at 8.

```{r}
knn8 <- knn2nb(knearneigh(coords, k=8))
knn8
```

The code chunk below is used to plot the adaptive distance based neighbours.

```{r}
plot(nga_wp$geometry, border="lightgrey")
plot(knn8, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```

**K-nearest neighbours method** is chosen as the spatial weighting method.

### 4.2 Row-standardised weight matrix

Next, we need to assign weights to each neighbouring polygon. In our case, each neighbouring will be assigned equal weight(Style "W").

```{r}
rsknn8 <- nb2listw(knn8, 
                   style="W", 
                   zero.policy = TRUE)
rsknn8
```

## 5. Global Spatial Autocorrelation: Moran's I

### 5.1 Moran's I Test

Null Hypothesis: The percentage of non-functional water points is randomly distributed in Nigeria.

Alternative Hypothesis: The percentage of non-functional water points has space autocorrelation in Nigeria.

The code chunk below performs Moran's I statistical testing using *moran.test()* of **spdep**.

```{r}
moran.test(nga_wp$`pct_non-functional`, 
           listw=rsknn8, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

The p-value is much smaller than alpha value at 0.05, so we have statistical evidence to reject the null hypothesis. The Moran's I value is 0.461388, larger than 0, indicating that the spatial distribution of high values or low values in the dataset is more spatially clustered.

#### 5.1.1 Computing Monte Carlo Moran's I

We can do a permutation test to evaluate the rank of the observed statistic in relation to the statistic of simulated values.

The code chunk below performs permutation test for Moran's I statistic by using *moran.mc()* of **spdep**. A total of 1000 simulation will be performed.

```{r}
set.seed(1234)
bperm= moran.mc(nga_wp$`pct_non-functional`, 
                listw=rsknn8, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

#### 5.1.2 Visualising Monte Carlo Moran's I

The code chunk below is used to plot the distribution of Monte Carlo test result.

```{r}
ggplot(mapping = aes(bperm$res))+
  geom_density(color="black", 
                 fill="light blue") +
  geom_vline(xintercept = 0.461388)
  labs(x = "Simulated Moran's I",
      y = "Frequency")
```

### 5.2 Computing Moran's I correlogram

In the code chunk below, *sp.correlogram()* of spdep package is used to compute a 8-lag spatial correlogram of percentage of non functional water points. The global spatial autocorrelation used in Moran's I. The plot() of base Graph is then used to plot the output.

```{r}
MI_corr <- sp.correlogram(knn8, 
                          nga_wp$`pct_non-functional`, 
                          order=8, 
                          method="I", 
                          style="W")
plot(MI_corr)
```

## 6. Cluster and Outlier Analysis

Local Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. Local Moran's I will be used to detect cluster and outlier from percentage of non-functional water point across Nigeria.

### 6.1 Computing local Moran's I

To compute local Moran's I, the *localmoran()* function of **spdep** will be used. It computes *Ii* values, given a set of *zi* values and a listw object providing neighbour weighting information for the polygon associated with the zi values.

The code chunk below is used to compute local Moran's I of *pct_non-functional water point* at the LGA level.

```{r}
fips1 <- order(nga_wp$`pct_non-functional`)
localMI <- localmoran(nga_wp$`pct_non-functional`, rsknn8)
head(localMI)
```

#### 6.1.1 Mapping local Moran's I values

Before mapping, it is wise to append the local Moran's I dataframe onto Nigeria Water Point dataframe. The new data frame is called *nga_wp.localMI*.

```{r}
nga_wp.localMI <- cbind(nga_wp,localMI) %>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

The code chunk below is used to plot the local Moran's I values.

```{r}
localMI.map <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_layout(legend.width=0.2,
          legend.height=0.3,
          legend.position=c("right","bottom")) +
  tm_borders(alpha = 0.5)
localMI.map
```

#### 6.1.2 Mapping local Moran's I p-values

Above choropleth shows the positive and negative values. Ans we can plot Moran's I p-values as well.

```{r}
pvalue.map <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_layout(legend.width=0.2,
          legend.height=0.3,
          legend.position=c("right","bottom")) +
  tm_borders(alpha = 0.5)
pvalue.map
```

#### 6.1.3 Mapping both local Moran's I values and p-values

```{r}
tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

### 6.2 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by types of spatial autocorrelation. The first step before we generate the LISA Cluster Map is to plot the Moran Scatterplot.

#### 6.2.1 Plotting Moran Scatterplot

The scatterplot shows the relationship between the chosen attribute ("pct of non-functional water points" in our case) at each location and the average value of the same attribute at neighbouring locations.

The code chunk below is used to plot the Moran Scatterplot.

```{r}
nci <- moran.plot(nga_wp$`pct_non-functional`, rsknn8,
                  labels=as.character(nga_wp$ADM2_EN), 
                  xlab="Percentage of non-functional Water Points", 
                  ylab="Spatially Lag Percentage of non-functional WPs")
```

The plot is split in 4 quadrants. The top right corner belongs to areas that have high percentage of non-functional water points.

#### 6.2.2 Plotting Moran Scatterplot with standardised variable

Firstly, we use *scale()* to centers and scales the variable.

```{r}
nga_wp$Z.pct_nonfunctional <- scale(nga_wp$`pct_non-functional`) %>% 
  as.vector 
```

Then we use code chunk below to plot again.

```{r}
nci2 <- moran.plot(nga_wp$Z.pct_nonfunctional, rsknn8,
                   labels=as.character(nga_wp$ADM2_EN),
                   xlab="z-Percentage of non-functional Water Points", 
                   ylab="Spatially Lag Percentage of non-functional WPs")
```

#### 6.2.3 Preparing LISA map classes

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Then, derive the spatially lagged variable of interest (i.e. Percentage of non-functional Water Points) and centers tha spatially lagged variable around its mean.

```{r}
nga_wp$lag_pctnonfuncional <- lag.listw(rsknn8, nga_wp$`pct_non-functional`)
DV <- nga_wp$lag_pctnonfuncional - mean(nga_wp$lag_pctnonfuncional)     
```

Then centering the local Moran's around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])    
```

We set the significance level at 0.05.

```{r}
signif <- 0.05 
```

The code chunk below is used to define four quadrants: **low-low (1), low-high (2), high-low (3) and high-high (4)**.

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

And place non-significant Moran in category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

#### 6.2.4 Plotting LISA Map

The code chunk below is used to plot the LISA Map.

```{r}
nga_wp.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

LISAMap <- tm_shape(nga_wp.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
LISAMap
```

For better visualisation, the code chunk below is used to plot local Moran's I values and insterested attribute together.

```{r}
tmap_arrange(pct_nonfunctional, LISAMap, asp=1, ncol=2)
```

The code chunk below is used plot the local Moran's I map and p-value map together.

```{r}
tmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)
```

### 6.3 Hot Spot and Cold Spot Area Analysis

"Hot Spot" refers to a region or value that is higher relative to its surroundings.

#### 6.3.1 Getis and Ord's G-statistics

G-statistics is an alternative spatial statistics to detect spatial anomalies. It looks at neighbours within a defined proximity to identify either high or low values cluster spatially.

There are three steps to do:

-   Deriving spatial weight matrix

-   Computing G-statistics

-   Mapping G-statistics

##### 6.3.1.1 Computing adaptive distance weight matrix

As we chose k-nearest neighbour methos as the spatial weighting method in Chapter 4.1.

Now we convert it into spatial weights object.

```{r}
knn_lw <- nb2listw(knn8, style = 'B')
summary(knn_lw)
```

#### 6.3.2 Computing G-statistics with adaptive distance weights

```{r}
fips <- order(nga_wp$`pct_non-functional`)
gi.adaptive <- localG(nga_wp$`pct_non-functional`, knn_lw)
gi.adaptive
```

Then we use code chunk below to join the Gi values to the corresponding Nigeria_Water Point sf data.

```{r}
nga_wp.gi <- cbind(nga_wp, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

#### 6.3.3 Mapping Gi values with adaptive distance weights

```{r}
Gimap <- tm_shape(nga_wp.gi) +
    tm_polygons(col = "gstat_adaptive", 
          style = "pretty", 
          palette="-RdBu", 
          title = "local Gi") + 
  tm_borders(alpha = 0.5)

tmap_arrange(pct_nonfunctional, Gimap, asp=1, ncol=2)
```
